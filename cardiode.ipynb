{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6665ac-a170-46c5-bfa1-5584871144a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARDIO:DE data structure:\n",
    "# data\n",
    "# └── cardiode\n",
    "#     ├── tsv\n",
    "#     |   ├── CARDIODE100_heldout\n",
    "#     |   │   └── *.tsv [x100]\n",
    "#     |   └── CARDIODE400_main\n",
    "#     |       └── *.tsv [x400]\n",
    "#     └── txt\n",
    "#         ├── CARDIODE100_heldout\n",
    "#         │   └── *.txt [x100]\n",
    "#         └── CARDIODE400_main \n",
    "#             └── *.txt [x400]\n",
    "#\n",
    "# Info:\n",
    "# - CARDIO:DE has no nested entites, therefore there is no need to remove them.\n",
    "# - The maximum length of a passage is 2195 characters, Llama2 can handle 4096 tokens (@Suteera: is this correct?), therefore this is fine.\n",
    "# - As agreed the following nomenclature applies:\n",
    "#    documents = dataset\n",
    "#    document  = dataset[index]\n",
    "#    entities  = dataset[index][\"entities\"]\n",
    "#    entity    = dataset[index][\"entities\"][index2] \n",
    "#      e.g. [{'id': '1-49-1', 'type': 'ACTIVEING', 'text': ['Salbutamol'], 'offsets': [[6055, 6065]], 'normalized': []}]\n",
    "#    passages  = dataset[index][\"passages\"]\n",
    "#    passage   = dataset[index][\"passages\"][index3] \n",
    "#      e.g. [{'id': '1-1', 'type': 'sentence', 'text': ['Some text'], 'offsets': [[0, 8]]},\n",
    "#    samples   = transformed data to a valid input structure suitable for Suteera's training script.\n",
    "#      e.g. {'sample_id': 49, 'doc_id': '1.tsv', 'doc': 'Some text.', 'prompt': None, 'label': [('Ezetimib', 'ACTIVEING')]}\n",
    "#      Note: all functions defined do not add the prompt to the samples, this needs to be done externally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97aecba-36ac-4cb6-a575-5918601e690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, disable_caching\n",
    "from scipy.special import rel_entr, kl_div\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b8385c-f814-46f7-a420-378824035145",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "def loadDataCardioDE() -> dict:\n",
    "    # Warnings are printed out due to not optimal loading in load_dataset(...). Printing the warnings will result in higher execution time.\n",
    "    dataset_name = \"bigbio/cardiode\"\n",
    "    data_dir = \"./data/cardiode\"\n",
    "    # Only train split available.\n",
    "    return load_dataset(dataset_name, split = \"train\", data_dir = data_dir, trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb13441c-6755-4fc4-ad30-dfa386d34891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the loaded dataset of CARDIO:DE into samples which are a valid input structure suitable for\n",
    "# training Llama2. Every sample is one document which has all passages concatenated.\n",
    "# \n",
    "# dataset: the dataset loaded with load_dataset.\n",
    "#\n",
    "# return: a list of samples, each contains one document. \n",
    "#\n",
    "def transformToSingleDocumentsCardioDE(dataset: dict) -> dict:\n",
    "    ret = [None] * len(dataset)\n",
    "\n",
    "    for index, document in enumerate(dataset):\n",
    "        ret[index] = {\n",
    "            \"sample_id\" : index,\n",
    "            \"doc_id\" : document[\"document_id\"],\n",
    "            \"doc\" : \"\",\n",
    "            \"prompt\" : None,\n",
    "            \"label\" : []\n",
    "        }\n",
    "        text = \"\"\n",
    "        for passage in document[\"passages\"]:\n",
    "            text += passage[\"text\"][0] + \" \"\n",
    "            \n",
    "        ret[index][\"doc\"] = text\n",
    "\n",
    "        # Container for the text and labels of entites.\n",
    "        text = []\n",
    "        label = []\n",
    "        \n",
    "        # Check which entities belong to the current passage.\n",
    "        for entity in document[\"entities\"]:\n",
    "            text.append(entity[\"text\"][0])\n",
    "            label.append(entity[\"type\"])\n",
    "\n",
    "        ret[index][\"label\"] = list(zip(text, label))\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6859a4da-ae9c-4507-89c1-75049e84724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the loaded dataset of CARDIO:DE into samples which are a valid input structure suitable for\n",
    "# training Llama2. Every sample is one single passage.\n",
    "# \n",
    "# dataset: the dataset loaded with load_dataset.\n",
    "#\n",
    "# return: a list of samples, each contains one passage. \n",
    "#\n",
    "def transformToSinglePassagesCardioDE(dataset: dict):\n",
    "    ret = []\n",
    "\n",
    "    # Each transformed passage gets it's own index.\n",
    "    idx = 0\n",
    "    for document in dataset:\n",
    "        for passage in document[\"passages\"]:\n",
    "\n",
    "            # Container for the text and labels of entites.\n",
    "            text = []\n",
    "            label = []\n",
    "\n",
    "            # Offset of the current passage.\n",
    "            passageoffsets = passage[\"offsets\"][0]\n",
    "\n",
    "            # Check which entities belong to the current passage.\n",
    "            for entity in document[\"entities\"]:\n",
    "                entityoffsets = entity[\"offsets\"][0]\n",
    "\n",
    "                # Check if entity is in the current passage.\n",
    "                if entityoffsets[0] > passageoffsets[0] and entityoffsets[1] < passageoffsets[1]:\n",
    "                    text.append(entity[\"text\"][0])\n",
    "                    label.append(entity[\"type\"])\n",
    "            \n",
    "            ret.append({\n",
    "                \"sample_id\": idx, \n",
    "                \"doc_id\":    document[\"document_id\"], \n",
    "                \"doc\":       passage[\"text\"][0], \n",
    "                \"prompt\":    None,\n",
    "                \"label\":     list(zip(text, label))\n",
    "            })\n",
    "            \n",
    "            idx += 1\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9600622-5835-484c-bf7e-a7696a8329f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary containig all entity names which can be found in CARDIO:DE as keys of the dictionary. \n",
    "# Since this function is used mostly for counting purposes, the values of each key is set to zero.\n",
    "# The dictionary is sorted.\n",
    "#\n",
    "# return: a dictionary containin all entity names as keys.\n",
    "#\n",
    "def getEntityNamesCardioDE() -> dict: \n",
    "    return dict(sorted({\n",
    "        \"ACTIVEING\" : 0, \n",
    "        \"DRUG\" :      0, \n",
    "        \"STRENGTH\" :  0, \n",
    "        \"FREQUENCY\" : 0, \n",
    "        \"DURATION\" :  0, \n",
    "        \"FORM\" :      0\n",
    "    }.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ef5eb0-c733-484b-91cc-0ee69ba9980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of entities in the given sample. If an entity is not found at all the count is set to \n",
    "# zero. \n",
    "#\n",
    "# return: a dictionary with the entity names as key and their counts as values. Nomenclature: sample_count.\n",
    "# \n",
    "def getEntityCountsCardioDE(sample) -> dict:\n",
    "    ret = getEntityNamesCardioDE()\n",
    "\n",
    "    for label in sample[\"label\"]:\n",
    "        ret[label[1]] += 1\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029356b8-0a11-4119-8b07-e68f54bb005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the numbner of entities to probability distributions which can be used to calculate the KL divergence. \n",
    "# Samples which do not contain any entity will result in a dictionary with zero entries.\n",
    "# Example:\n",
    "#   {\"ACTIVEING\" : 1    , \"DRUG\" :      3    , \"STRENGTH\" :  0, \"FREQUENCY\" : 1    , \"DURATION\" :  2   , \"FORM\" :      1}\n",
    "#   will be converted into:\n",
    "#   {\"ACTIVEING\" : 0.125, \"DRUG\" :      0.375, \"STRENGTH\" :  0, \"FREQUENCY\" : 0.125, \"DURATION\" :  0.25, \"FORM\" :      0.125}\n",
    "#\n",
    "# return: a dictionary containing the probability distribution of the entites in the given sample. Nomenclature: sample_distribution\n",
    "#\n",
    "def toDistributionCardioDE(sample_count: dict) -> dict: \n",
    "    ret = sample_count.copy()\n",
    "\n",
    "    # Total amount of entites found in the sample.\n",
    "    total = sum(ret.values())\n",
    "\n",
    "    # If the sample contains entites.\n",
    "    if (total > 0):\n",
    "        for entity in ret:\n",
    "            ret[entity] = ret[entity] / total\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d97637-e43e-4a50-a31d-b12cc77502d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the average probability distribution of entites in CARDIO:DE.\n",
    "# \n",
    "# sample_counts: a list/array of \"sample_count\" which you can get with the function \"getEntityCountsCardioDE\".\n",
    "#\n",
    "# return: a dictionary with the average probability distribution of entites in CARDIO:DE.\n",
    "#\n",
    "def getAverageDistributionCardioDE(sample_counts: list) -> dict:\n",
    "    ret = getEntityNamesCardioDE()\n",
    "\n",
    "    # Summing up the amount of each entity.\n",
    "    for sample_count in sample_counts:\n",
    "        for entity in sample_count:\n",
    "            ret[entity] += sample_count[entity]\n",
    "\n",
    "    # Returning the probability distribution.\n",
    "    return toDistributionCardioDE(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3825206-7512-45ea-a2db-feaca5ececed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the KL divegence of a sample distribution w.r.t. the average distribution.\n",
    "# \n",
    "# sample_distribution: the entity distribution of the sample.\n",
    "# average_distribution: the average distribution of the sample.\n",
    "#\n",
    "# return: the divergence as float number. This could be also infinity, if the sample has no \n",
    "#   entities.\n",
    "#\n",
    "def getKLDivergenceCardioDE(sample_distribution: dict, average_distribution: dict) -> float:\n",
    "    divergence = kl_div(list(average_distribution.values()), list(sample_distribution.values()))\n",
    "    divergence = list(filter(lambda x: x != float('inf'), divergence))\n",
    "\n",
    "    if len(divergence) == 0:\n",
    "        return float('inf')\n",
    "    else:\n",
    "        return sum(divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb69e917-6711-4006-8b65-11bf8466b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the divergence of the samples and sorts them in a new list based on it. \n",
    "#\n",
    "def sortSamplesByDivergenceCardioDE(samples) -> list:\n",
    "\n",
    "    # Calculating the count of each sample.\n",
    "    sample_counts = []\n",
    "    for sample in samples:\n",
    "        sample_counts.append(getEntityCountsCardioDE(sample))\n",
    "\n",
    "    average_distribution = getAverageDistributionCardioDE(sample_counts)\n",
    "\n",
    "    # Calculating the divergences of each sample.\n",
    "    sample_divergences = []\n",
    "    \n",
    "    for sample_count in sample_counts:\n",
    "        sample_divergences.append(getKLDivergenceCardioDE(toDistributionCardioDE(sample_count), average_distribution))\n",
    "\n",
    "    # Adding the divergence to the sample.\n",
    "    for index, sample in enumerate(samples):\n",
    "        sample[\"divergence\"] = sample_divergences[index]\n",
    "        \n",
    "    return sorted(samples, key = lambda x: x['divergence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3734dd6a-8125-4c12-8239-e3c93f28aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the amount of samples which are requested. If the amount is below 1 and greater than 0, it will\n",
    "# be treated as percentage, if it is below 0, the whole dataset will be returned, if it is above 1, the given\n",
    "# amount of samples are returned.\n",
    "# \n",
    "# samples: the whole set of samples.\n",
    "# amount: the amount of samples requested.\n",
    "#\n",
    "# return: a sorted list with the requested amount of samples which have the most similar distribution as the \n",
    "#     average sample. \n",
    "#\n",
    "def getRankedSamplesCardioDE(samples: list, amount: float = -1) -> list:\n",
    "    # Correcting amount if it is negative.\n",
    "    if amount < 0:\n",
    "        amount = len(samples)\n",
    "    else:\n",
    "        # Also percentages are acceptable.\n",
    "        if amount < 1:\n",
    "            amount = round(amount * len(samples))\n",
    "\n",
    "    # Get the sorted samples.\n",
    "    sorted_samples = sortSamplesByDivergenceCardioDE(samples)\n",
    "\n",
    "    return sorted_samples[0:amount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0c99ea1-8ef1-4977-9d70-788993630586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the dataset, shuffle the data based on the seed, ranks the data based on the average sample of the\n",
    "# dataset and returns the requested amount of samples.\n",
    "#\n",
    "# amount: the amount of samples requested. Look at \"getRankedSamplesCardioDE\" for more information.\n",
    "# seed: the seed used to shuffle the samples.\n",
    "#\n",
    "# return: a list of samples with \"amount\" length containing the samples  which have the most similar \n",
    "#     distribution as the average sample. \n",
    "def cardioDE(amount: float = -1, seed: int = 42, train_split: float = 0.7, test_split: float = 0.15) -> list:\n",
    "    dataset = loadDataCardioDE()\n",
    "    documents = transformToSingleDocumentsCardioDE(dataset)\n",
    "    \n",
    "    # Randomize the data.\n",
    "    random.seed(seed)\n",
    "    random.shuffle(documents)\n",
    "\n",
    "    train_amount = round(len(documents) * train_split)\n",
    "    test_amount = round(len(documents) * test_split)\n",
    "\n",
    "    train = documents[0: train_amount]\n",
    "    test = documents[train_amount: train_amount + test_amount]\n",
    "    dev = documents[train_amount + test_amount:len(documents)]\n",
    "\n",
    "    return {\n",
    "        \"train\" : getRankedSamplesCardioDE(train, amount = amount), \n",
    "        \"test\" : test,\n",
    "        \"dev\" : dev\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5594596d-00a5-479b-bf42-bfaba83df345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example:\n",
    "samples = cardioDE(amount = -1, seed = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6491656-4b6c-49e2-9e3d-31d74d624c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8.19",
   "language": "python",
   "name": "python3.8.19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
